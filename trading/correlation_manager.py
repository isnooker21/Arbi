"""
‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Correlation ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á

‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà:
- ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ñ‡∏π‡πà‡πÄ‡∏á‡∏¥‡∏ô (Correlation)
- ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô (Stuck Positions)
- ‡∏´‡∏≤‡∏Ñ‡∏π‡πà‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô
- ‡πÉ‡∏ä‡πâ AI ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô
- ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Grid Trading ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô:
1. ‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á EUR/USD ‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô
2. ‡∏´‡∏≤‡∏Ñ‡∏π‡πà‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏™‡∏π‡∏á ‡πÄ‡∏ä‡πà‡∏ô GBP/USD
3. ‡πÉ‡∏ä‡πâ AI ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏Å‡∏≤‡∏£‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô
4. ‡πÄ‡∏õ‡∏¥‡∏î‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á GBP/USD ‡πÉ‡∏ô‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import logging
from typing import Dict, List, Tuple, Optional
import threading

class CorrelationManager:
    def __init__(self, broker_api, ai_engine):
        self.broker = broker_api
        self.ai = ai_engine
        self.correlation_matrix = {}
        self.recovery_positions = {}
        self.is_running = False
        self.logger = logging.getLogger(__name__)
        
    def start_correlation_monitoring(self):
        """Start correlation monitoring and recovery system"""
        self.is_running = True
        self.logger.info("Starting correlation monitoring...")
        
        # Run in separate thread
        monitoring_thread = threading.Thread(target=self._monitoring_loop, daemon=True)
        monitoring_thread.start()
    
    def stop_correlation_monitoring(self):
        """Stop correlation monitoring"""
        self.is_running = False
        self.logger.info("Stopping correlation monitoring...")
    
    def _monitoring_loop(self):
        """Main monitoring loop"""
        self.logger.info("üîó Correlation monitoring started")
        
        while self.is_running:
            try:
                # Update correlation matrix every 5 minutes
                self.calculate_correlations()
                
                # Check for recovery opportunities
                self.check_recovery_opportunities()
                
                # Sleep for 5 minutes
                threading.Event().wait(300)
                
            except Exception as e:
                self.logger.error(f"Correlation monitoring error: {e}")
                threading.Event().wait(60)
        
        self.logger.info("üîó Correlation monitoring stopped")
    
    def calculate_correlations(self, lookback_days: int = 30, timeframes: List[str] = ['H1', 'H4', 'D1']):
        """
        ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì correlation matrix ‡πÅ‡∏ö‡∏ö‡∏Ç‡∏¢‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ multiple timeframes ‡πÅ‡∏•‡∏∞ weighted correlation
        
        Parameters:
        - lookback_days: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì (default: 30 ‡∏ß‡∏±‡∏ô)
        - timeframes: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ timeframes ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ ['H1', 'H4', 'D1']
        """
        try:
            pairs = self.broker.get_available_pairs()
            
            if not pairs:
                self.logger.warning("No pairs available for correlation calculation")
                return {}
            
            correlations = {}
            
            for pair1 in pairs:
                correlations[pair1] = {}
                
                for pair2 in pairs:
                    if pair1 != pair2:
                        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì correlation ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ timeframe
                        correlation_scores = []
                        weights = []
                        
                        for tf in timeframes:
                            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ timeframe
                            hours = lookback_days * 24 if tf == 'H1' else (lookback_days * 6 if tf == 'H4' else lookback_days)
                            
                            data1 = self.broker.get_historical_data(pair1, tf, hours)
                            data2 = self.broker.get_historical_data(pair2, tf, hours)
                            
                            if self._validate_correlation_data(data1, data2):
                                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì weighted correlation ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö timeframe ‡∏ô‡∏µ‡πâ
                                correlation = self._calculate_weighted_correlation(data1, data2)
                                correlation_scores.append(correlation)
                                
                                # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î weight: H1=0.5, H4=0.3, D1=0.2
                                weight = 0.5 if tf == 'H1' else (0.3 if tf == 'H4' else 0.2)
                                weights.append(weight)
                        
                        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì weighted average correlation
                        if correlation_scores:
                            final_correlation = sum(c*w for c, w in zip(correlation_scores, weights)) / sum(weights)
                            correlations[pair1][pair2] = final_correlation
                        else:
                            correlations[pair1][pair2] = 0.0
            
            self.correlation_matrix = correlations
            self.logger.info(f"Updated enhanced correlation matrix for {len(pairs)} pairs using {lookback_days} days")
            return correlations
            
        except Exception as e:
            self.logger.error(f"Error calculating enhanced correlations: {e}")
            return {}
    
    def calculate_pair_correlation(self, data1: pd.DataFrame, data2: pd.DataFrame) -> float:
        """Calculate correlation between two pairs"""
        try:
            # Align data by timestamp
            merged = pd.merge(data1[['close']], data2[['close']], 
                            left_index=True, right_index=True, 
                            suffixes=('_1', '_2'))
            
            if len(merged) < 10:
                return 0.0
            
            # Calculate returns
            returns1 = merged['close_1'].pct_change().dropna()
            returns2 = merged['close_2'].pct_change().dropna()
            
            # Align returns
            aligned_returns = pd.merge(returns1, returns2, left_index=True, right_index=True)
            
            if len(aligned_returns) < 5:
                return 0.0
            
            # Calculate correlation
            correlation = aligned_returns['close_1'].corr(aligned_returns['close_2'])
            
            return correlation if not np.isnan(correlation) else 0.0
            
        except Exception as e:
            self.logger.error(f"Error calculating pair correlation: {e}")
            return 0.0
    
    def _validate_correlation_data(self, data1: pd.DataFrame, data2: pd.DataFrame) -> bool:
        """
        ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì correlation
        
        Parameters:
        - data1, data2: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DataFrame
        
        Returns:
        - True ‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á, False ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
        """
        try:
            if data1 is None or data2 is None:
                return False
            
            if len(data1) < 10 or len(data2) < 10:
                return False
            
            if len(data1) != len(data2):
                return False
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤
            if data1['close'].isna().any() or data2['close'].isna().any():
                return False
            
            return True
            
        except Exception as e:
            self.logger.error(f"Error validating correlation data: {e}")
            return False
    
    def _calculate_weighted_correlation(self, data1: pd.DataFrame, data2: pd.DataFrame, 
                                      decay_factor: float = 0.1) -> float:
        """
        ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì weighted correlation ‡πÇ‡∏î‡∏¢‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
        
        Parameters:
        - data1, data2: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DataFrame
        - decay_factor: ‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏Å‡∏≤‡∏£‡∏•‡∏î‡∏•‡∏á (‡∏¢‡∏¥‡πà‡∏á‡∏°‡∏≤‡∏Å‡∏¢‡∏¥‡πà‡∏á‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î)
        
        Returns:
        - Weighted correlation coefficient
        """
        try:
            # Align data by timestamp
            merged = pd.merge(data1[['close']], data2[['close']], 
                            left_index=True, right_index=True, 
                            suffixes=('_1', '_2'))
            
            if len(merged) < 10:
                return 0.0
            
            # Calculate returns
            returns1 = merged['close_1'].pct_change().dropna()
            returns2 = merged['close_2'].pct_change().dropna()
            
            # Align returns
            aligned_returns = pd.merge(returns1, returns2, left_index=True, right_index=True)
            
            if len(aligned_returns) < 5:
                return 0.0
            
            # Create weights (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏°‡∏µ weight ‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤)
            n = len(aligned_returns)
            weights = np.exp(-decay_factor * np.arange(n-1, -1, -1))
            weights = weights / weights.sum()  # Normalize weights
            
            # Calculate weighted correlation
            data1_array = aligned_returns['close_1'].values
            data2_array = aligned_returns['close_2'].values
            
            # Weighted covariance
            mean1 = np.average(data1_array, weights=weights)
            mean2 = np.average(data2_array, weights=weights)
            
            cov = np.average((data1_array - mean1) * (data2_array - mean2), weights=weights)
            var1 = np.average((data1_array - mean1) ** 2, weights=weights)
            var2 = np.average((data2_array - mean2) ** 2, weights=weights)
            
            if var1 == 0 or var2 == 0:
                return 0.0
            
            correlation = cov / np.sqrt(var1 * var2)
            
            return correlation if not np.isnan(correlation) else 0.0
            
        except Exception as e:
            self.logger.error(f"Error calculating weighted correlation: {e}")
            return 0.0
    
    def find_recovery_opportunities(self, stuck_positions: List[Dict]) -> List[Dict]:
        """Find correlation pairs for recovery"""
        recovery_opportunities = []
        
        try:
            for position in stuck_positions:
                pair = position['symbol']
                current_pnl = position.get('unrealized_pnl', 0)
                
                # Only look for recovery if position is losing
                if current_pnl >= 0:
                    continue
                
                # Find highly correlated pairs
                if pair in self.correlation_matrix:
                    for corr_pair, correlation in self.correlation_matrix[pair].items():
                        if abs(correlation) > 0.6:  # Minimum correlation threshold
                            
                            # Determine suggested direction
                            if correlation > 0:
                                # Positive correlation - opposite direction
                                suggested_direction = 'opposite'
                            else:
                                # Negative correlation - same direction
                                suggested_direction = 'same'
                            
                            opportunity = {
                                'base_pair': pair,
                                'recovery_pair': corr_pair,
                                'correlation': correlation,
                                'suggested_direction': suggested_direction,
                                'base_pnl': current_pnl,
                                'base_volume': position.get('volume', 0),
                                'timestamp': datetime.now()
                            }
                            
                            recovery_opportunities.append(opportunity)
            
            self.logger.info(f"Found {len(recovery_opportunities)} recovery opportunities")
            return recovery_opportunities
            
        except Exception as e:
            self.logger.error(f"Error finding recovery opportunities: {e}")
            return []
    
    def check_recovery_opportunities(self):
        """Check for recovery opportunities and execute if approved by AI"""
        try:
            # Get stuck positions (losing positions older than 1 hour)
            stuck_positions = self.broker.get_stuck_positions()
            
            if not stuck_positions:
                return
            
            # Find recovery opportunities
            recovery_opportunities = self.find_recovery_opportunities(stuck_positions)
            
            for opportunity in recovery_opportunities:
                # AI evaluation for recovery
                ai_decision = self.ai.evaluate_recovery_opportunity(opportunity)
                
                if ai_decision.should_act and ai_decision.confidence > 0.6:
                    self.logger.info(f"Executing recovery for {opportunity['base_pair']} "
                                   f"using {opportunity['recovery_pair']}")
                    self.execute_recovery_strategy(opportunity, ai_decision)
                    
        except Exception as e:
            self.logger.error(f"Error checking recovery opportunities: {e}")
    
    def execute_recovery_strategy(self, opportunity: Dict, ai_decision):
        """Execute correlation-based recovery"""
        try:
            base_pair = opportunity['base_pair']
            recovery_pair = opportunity['recovery_pair']
            direction = opportunity['suggested_direction']
            
            # Calculate position size based on correlation strength
            correlation_strength = abs(opportunity['correlation'])
            base_volume = opportunity['base_volume']
            
            # Scale position size based on correlation
            recovery_volume = base_volume * correlation_strength * ai_decision.position_size_multiplier
            
            # Determine order direction
            if direction == 'opposite':
                # If positive correlation, trade opposite direction
                order_type = 'SELL' if opportunity['correlation'] > 0 else 'BUY'
            else:
                # If negative correlation, trade same direction
                order_type = 'BUY' if opportunity['correlation'] < 0 else 'SELL'
            
            # Place recovery order
            order = self.broker.place_order(recovery_pair, order_type, recovery_volume)
            
            if order:
                # Store recovery position
                recovery_id = f"{base_pair}_{recovery_pair}_{datetime.now().timestamp()}"
                self.recovery_positions[recovery_id] = {
                    'base_pair': base_pair,
                    'recovery_pair': recovery_pair,
                    'order': order,
                    'correlation': opportunity['correlation'],
                    'entry_time': datetime.now(),
                    'ai_decision': ai_decision,
                    'status': 'active'
                }
                
                self.logger.info(f"Recovery order placed: {recovery_pair} {order_type} "
                               f"{recovery_volume} (Correlation: {opportunity['correlation']:.3f})")
                return True
            else:
                self.logger.error(f"Failed to place recovery order for {recovery_pair}")
                return False
                
        except Exception as e:
            self.logger.error(f"Error executing recovery strategy: {e}")
            return False
    
    def calculate_grid_levels(self, opportunity: Dict, num_levels: int = 5) -> List[Dict]:
        """Calculate grid levels for recovery strategy"""
        try:
            recovery_pair = opportunity['recovery_pair']
            current_price = self.broker.get_current_price(recovery_pair)
            
            if current_price is None:
                return []
            
            # Calculate grid spacing based on volatility
            volatility = self._calculate_pair_volatility(recovery_pair)
            grid_spacing = volatility * 0.5  # 50% of volatility
            
            levels = []
            for i in range(num_levels):
                level_price = current_price + (i + 1) * grid_spacing
                level_price_down = current_price - (i + 1) * grid_spacing
                
                levels.append({
                    'level': i + 1,
                    'price_up': level_price,
                    'price_down': level_price_down,
                    'lot_size': opportunity['base_volume'] * (0.5 ** i),  # Decreasing lot sizes
                    'direction_up': 'BUY',
                    'direction_down': 'SELL'
                })
            
            return levels
            
        except Exception as e:
            self.logger.error(f"Error calculating grid levels: {e}")
            return []
    
    def should_enter_grid_level(self, level: Dict) -> bool:
        """Check if should enter a specific grid level"""
        try:
            # Check if price has reached the level
            current_price = self.broker.get_current_price(level['recovery_pair'])
            
            if current_price is None:
                return False
            
            # Check if price is within 5 pips of the level
            price_tolerance = 0.0005
            
            return (abs(current_price - level['price_up']) < price_tolerance or
                   abs(current_price - level['price_down']) < price_tolerance)
                   
        except Exception as e:
            self.logger.error(f"Error checking grid level entry: {e}")
            return False
    
    def _calculate_pair_volatility(self, pair: str) -> float:
        """Calculate volatility for a specific pair"""
        try:
            data = self.broker.get_historical_data(pair, 'H1', 24)
            
            if data is None or len(data) < 10:
                return 0.001  # Default volatility
            
            returns = data['close'].pct_change().dropna()
            return returns.std()
            
        except Exception as e:
            self.logger.error(f"Error calculating volatility for {pair}: {e}")
            return 0.001
    
    def get_correlation_matrix(self) -> Dict:
        """Get current correlation matrix"""
        return self.correlation_matrix
    
    def get_recovery_positions(self) -> Dict:
        """Get all active recovery positions"""
        return self.recovery_positions
    
    def close_recovery_position(self, recovery_id: str, reason: str = "manual"):
        """Close a specific recovery position"""
        try:
            if recovery_id not in self.recovery_positions:
                return False
            
            recovery_data = self.recovery_positions[recovery_id]
            order = recovery_data['order']
            
            # Close the order
            success = self.broker.close_order(order['order_id'])
            
            if success:
                recovery_data['status'] = 'closed'
                recovery_data['close_time'] = datetime.now()
                recovery_data['close_reason'] = reason
                
                self.logger.info(f"Closed recovery position {recovery_id} - Reason: {reason}")
                return True
            else:
                self.logger.error(f"Failed to close recovery position {recovery_id}")
                return False
                
        except Exception as e:
            self.logger.error(f"Error closing recovery position {recovery_id}: {e}")
            return False
    
    def get_correlation_performance(self) -> Dict:
        """Get performance statistics for correlation system"""
        total_recoveries = len(self.recovery_positions)
        active_recoveries = sum(1 for r in self.recovery_positions.values() if r['status'] == 'active')
        closed_recoveries = sum(1 for r in self.recovery_positions.values() if r['status'] == 'closed')
        
        return {
            'total_recoveries': total_recoveries,
            'active_recoveries': active_recoveries,
            'closed_recoveries': closed_recoveries,
            'correlation_pairs_tracked': len(self.correlation_matrix)
        }
